{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "# import psutil\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"train\"\n",
    "validation_data_path = \"valid\"\n",
    "test_data_path = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "# channel = (3, )\n",
    "input_shape = (img_width, img_height)\n",
    "# input_shape = tf.expand_dims(input_shape , -1)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260915 images belonging to 14 classes.\n",
      "Found 47531 images belonging to 14 classes.\n",
      "Found 130645 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_path,\n",
    "    target_size=input_shape,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_path,\n",
    "                                                  target_size=input_shape,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "def tf_data_generator(generator, input_shape):\n",
    "    num_class = generator.num_classes\n",
    "    print(num_class)\n",
    "    tf_generator = tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=([None, input_shape[0], input_shape[1]],\n",
    "                       [None, num_class])\n",
    "    )\n",
    "    return tf_generator\n",
    "\n",
    "\n",
    "train_data = tf_data_generator(train_generator, input_shape)\n",
    "test_data = tf_data_generator(test_generator, input_shape)\n",
    "val_data = tf_data_generator(validation_generator, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "def create_model(img_width, img_height, num_classes):\n",
    "    # base_model = VGG16(include_top=False, weights=\"imagenet\")\n",
    "\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape + (3,),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        classes=num_classes,\n",
    "    )\n",
    "\n",
    "    input_layer = Input(shape=(img_width, img_height, 3))\n",
    "\n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Combine the input layer and the pre-trained model\n",
    "    x = base_model(input_layer)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "    for layer in base_model.layers[-5:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Add the output layer\n",
    "    output_layer = Dense(units=num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Create and return the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model(img_width, img_height, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\", \"categorical_crossentropy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model_viz = tf.keras.utils.plot_model(model,\n",
    "                                      to_file='model.png',\n",
    "                                      show_shapes=True,\n",
    "                                      show_layer_names=True,\n",
    "                                      rankdir='TB',\n",
    "                                      expand_nested=True,\n",
    "                                      dpi=55)\n",
    "model_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "254/254 [==============================] - 151s 580ms/step - loss: 2.4053 - accuracy: 0.2179 - categorical_crossentropy: 2.4053 - val_loss: 6.4943 - val_accuracy: 0.1834 - val_categorical_crossentropy: 6.4943\n",
      "Epoch 2/20\n",
      "254/254 [==============================] - 137s 540ms/step - loss: 2.2865 - accuracy: 0.2536 - categorical_crossentropy: 2.2865 - val_loss: 3.2452 - val_accuracy: 0.2140 - val_categorical_crossentropy: 3.2452\n",
      "Epoch 3/20\n",
      "254/254 [==============================] - 138s 544ms/step - loss: 2.2116 - accuracy: 0.2801 - categorical_crossentropy: 2.2116 - val_loss: 3.0100 - val_accuracy: 0.2758 - val_categorical_crossentropy: 3.0100\n",
      "Epoch 4/20\n",
      "254/254 [==============================] - 137s 540ms/step - loss: 2.1892 - accuracy: 0.2912 - categorical_crossentropy: 2.1892 - val_loss: 3.5515 - val_accuracy: 0.2174 - val_categorical_crossentropy: 3.5515\n",
      "Epoch 5/20\n",
      "254/254 [==============================] - 136s 534ms/step - loss: 2.1676 - accuracy: 0.2952 - categorical_crossentropy: 2.1676 - val_loss: 3.8180 - val_accuracy: 0.1705 - val_categorical_crossentropy: 3.8180\n",
      "Epoch 6/20\n",
      "254/254 [==============================] - 135s 533ms/step - loss: 2.1519 - accuracy: 0.3004 - categorical_crossentropy: 2.1519 - val_loss: 3.1407 - val_accuracy: 0.2500 - val_categorical_crossentropy: 3.1407\n",
      "Epoch 7/20\n",
      "254/254 [==============================] - 133s 523ms/step - loss: 2.1406 - accuracy: 0.3141 - categorical_crossentropy: 2.1406 - val_loss: 2.9005 - val_accuracy: 0.2595 - val_categorical_crossentropy: 2.9005\n",
      "Epoch 8/20\n",
      "254/254 [==============================] - 132s 521ms/step - loss: 2.1270 - accuracy: 0.3081 - categorical_crossentropy: 2.1270 - val_loss: 3.1752 - val_accuracy: 0.2412 - val_categorical_crossentropy: 3.1752\n",
      "Epoch 9/20\n",
      "254/254 [==============================] - 137s 539ms/step - loss: 2.1255 - accuracy: 0.3097 - categorical_crossentropy: 2.1255 - val_loss: 2.7870 - val_accuracy: 0.2826 - val_categorical_crossentropy: 2.7870\n",
      "Epoch 10/20\n",
      "254/254 [==============================] - 139s 547ms/step - loss: 2.1157 - accuracy: 0.3113 - categorical_crossentropy: 2.1157 - val_loss: 3.6088 - val_accuracy: 0.1963 - val_categorical_crossentropy: 3.6088\n",
      "Epoch 11/20\n",
      "254/254 [==============================] - 130s 511ms/step - loss: 2.1303 - accuracy: 0.3129 - categorical_crossentropy: 2.1303 - val_loss: 3.2616 - val_accuracy: 0.2629 - val_categorical_crossentropy: 3.2616\n",
      "Epoch 12/20\n",
      "254/254 [==============================] - 131s 518ms/step - loss: 2.0991 - accuracy: 0.3206 - categorical_crossentropy: 2.0991 - val_loss: 3.4991 - val_accuracy: 0.2167 - val_categorical_crossentropy: 3.4991\n",
      "Epoch 13/20\n",
      "254/254 [==============================] - 126s 497ms/step - loss: 2.0952 - accuracy: 0.3284 - categorical_crossentropy: 2.0952 - val_loss: 3.1475 - val_accuracy: 0.2208 - val_categorical_crossentropy: 3.1475\n",
      "Epoch 14/20\n",
      "254/254 [==============================] - 125s 492ms/step - loss: 2.0886 - accuracy: 0.3193 - categorical_crossentropy: 2.0886 - val_loss: 2.8571 - val_accuracy: 0.2758 - val_categorical_crossentropy: 2.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d38a7d6fb0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator) // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(\n",
    "        validation_generator) // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
